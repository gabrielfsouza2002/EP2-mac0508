{
  "best_global_step": 3726,
  "best_metric": 3.1997548023108404,
  "best_model_checkpoint": "/content/drive/MyDrive/TupiTranslation_EP2/models/pt_to_ta/checkpoint-3726",
  "epoch": 6.0,
  "eval_steps": 500,
  "global_step": 3726,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08051529790660225,
      "grad_norm": 0.7360477447509766,
      "learning_rate": 0.00013101604278074866,
      "loss": 11.9159,
      "step": 50
    },
    {
      "epoch": 0.1610305958132045,
      "grad_norm": 0.545905351638794,
      "learning_rate": 0.0002647058823529412,
      "loss": 9.9999,
      "step": 100
    },
    {
      "epoch": 0.24154589371980675,
      "grad_norm": 1.0235588550567627,
      "learning_rate": 0.00039839572192513367,
      "loss": 9.5049,
      "step": 150
    },
    {
      "epoch": 0.322061191626409,
      "grad_norm": 0.6284688115119934,
      "learning_rate": 0.0004983046058208533,
      "loss": 9.2864,
      "step": 200
    },
    {
      "epoch": 0.4025764895330113,
      "grad_norm": 0.5263952016830444,
      "learning_rate": 0.0004912404634077423,
      "loss": 9.2239,
      "step": 250
    },
    {
      "epoch": 0.4830917874396135,
      "grad_norm": 0.5756484866142273,
      "learning_rate": 0.0004841763209946313,
      "loss": 9.1606,
      "step": 300
    },
    {
      "epoch": 0.5636070853462157,
      "grad_norm": 0.7594614028930664,
      "learning_rate": 0.00047711217858152025,
      "loss": 9.1563,
      "step": 350
    },
    {
      "epoch": 0.644122383252818,
      "grad_norm": 0.6256316900253296,
      "learning_rate": 0.0004700480361684092,
      "loss": 9.1211,
      "step": 400
    },
    {
      "epoch": 0.7246376811594203,
      "grad_norm": 0.576659083366394,
      "learning_rate": 0.0004629838937552981,
      "loss": 9.0093,
      "step": 450
    },
    {
      "epoch": 0.8051529790660226,
      "grad_norm": 0.6327356696128845,
      "learning_rate": 0.00045591975134218703,
      "loss": 9.0834,
      "step": 500
    },
    {
      "epoch": 0.8856682769726248,
      "grad_norm": 0.5649831295013428,
      "learning_rate": 0.000448855608929076,
      "loss": 9.0689,
      "step": 550
    },
    {
      "epoch": 0.966183574879227,
      "grad_norm": 0.6384204626083374,
      "learning_rate": 0.000441791466515965,
      "loss": 9.0878,
      "step": 600
    },
    {
      "epoch": 1.0,
      "eval_bleu": 0.2845525105600804,
      "eval_loss": 9.005538940429688,
      "eval_runtime": 149.5237,
      "eval_samples_per_second": 7.123,
      "eval_steps_per_second": 0.896,
      "step": 621
    },
    {
      "epoch": 1.0466988727858293,
      "grad_norm": 0.606191098690033,
      "learning_rate": 0.0004347273241028539,
      "loss": 9.0803,
      "step": 650
    },
    {
      "epoch": 1.1272141706924317,
      "grad_norm": 0.6365987062454224,
      "learning_rate": 0.0004276631816897429,
      "loss": 9.0688,
      "step": 700
    },
    {
      "epoch": 1.2077294685990339,
      "grad_norm": 0.7013275623321533,
      "learning_rate": 0.0004205990392766318,
      "loss": 9.0682,
      "step": 750
    },
    {
      "epoch": 1.288244766505636,
      "grad_norm": 0.6265172362327576,
      "learning_rate": 0.0004135348968635208,
      "loss": 8.9936,
      "step": 800
    },
    {
      "epoch": 1.3687600644122382,
      "grad_norm": 0.766904890537262,
      "learning_rate": 0.00040647075445040973,
      "loss": 8.9864,
      "step": 850
    },
    {
      "epoch": 1.4492753623188406,
      "grad_norm": 0.5312180519104004,
      "learning_rate": 0.00039940661203729865,
      "loss": 8.9929,
      "step": 900
    },
    {
      "epoch": 1.529790660225443,
      "grad_norm": 0.6472494602203369,
      "learning_rate": 0.00039234246962418763,
      "loss": 8.8539,
      "step": 950
    },
    {
      "epoch": 1.6103059581320451,
      "grad_norm": 0.5360122323036194,
      "learning_rate": 0.00038527832721107656,
      "loss": 8.9793,
      "step": 1000
    },
    {
      "epoch": 1.6908212560386473,
      "grad_norm": 0.7853188514709473,
      "learning_rate": 0.00037821418479796554,
      "loss": 9.0061,
      "step": 1050
    },
    {
      "epoch": 1.7713365539452495,
      "grad_norm": 0.7302872538566589,
      "learning_rate": 0.0003711500423848545,
      "loss": 8.8459,
      "step": 1100
    },
    {
      "epoch": 1.8518518518518519,
      "grad_norm": 0.6054334044456482,
      "learning_rate": 0.00036408589997174344,
      "loss": 8.8688,
      "step": 1150
    },
    {
      "epoch": 1.9323671497584543,
      "grad_norm": 0.5597894787788391,
      "learning_rate": 0.00035702175755863237,
      "loss": 8.7757,
      "step": 1200
    },
    {
      "epoch": 2.0,
      "eval_bleu": 0.6788423652631711,
      "eval_loss": 8.867828369140625,
      "eval_runtime": 130.1351,
      "eval_samples_per_second": 8.184,
      "eval_steps_per_second": 1.03,
      "step": 1242
    },
    {
      "epoch": 2.0128824476650564,
      "grad_norm": 0.5756368041038513,
      "learning_rate": 0.00034995761514552135,
      "loss": 8.9022,
      "step": 1250
    },
    {
      "epoch": 2.0933977455716586,
      "grad_norm": 0.7317877411842346,
      "learning_rate": 0.0003428934727324103,
      "loss": 8.8851,
      "step": 1300
    },
    {
      "epoch": 2.1739130434782608,
      "grad_norm": 0.6779297590255737,
      "learning_rate": 0.00033582933031929926,
      "loss": 8.8761,
      "step": 1350
    },
    {
      "epoch": 2.2544283413848634,
      "grad_norm": 0.7791202664375305,
      "learning_rate": 0.0003287651879061882,
      "loss": 8.8472,
      "step": 1400
    },
    {
      "epoch": 2.3349436392914655,
      "grad_norm": 0.8320106267929077,
      "learning_rate": 0.00032170104549307716,
      "loss": 8.8854,
      "step": 1450
    },
    {
      "epoch": 2.4154589371980677,
      "grad_norm": 0.6058112382888794,
      "learning_rate": 0.00031463690307996614,
      "loss": 8.8772,
      "step": 1500
    },
    {
      "epoch": 2.49597423510467,
      "grad_norm": 0.5968464612960815,
      "learning_rate": 0.000307572760666855,
      "loss": 8.8684,
      "step": 1550
    },
    {
      "epoch": 2.576489533011272,
      "grad_norm": 0.8909234404563904,
      "learning_rate": 0.000300508618253744,
      "loss": 8.7878,
      "step": 1600
    },
    {
      "epoch": 2.6570048309178746,
      "grad_norm": 0.6264939904212952,
      "learning_rate": 0.0002934444758406329,
      "loss": 8.9237,
      "step": 1650
    },
    {
      "epoch": 2.7375201288244764,
      "grad_norm": 0.9825460314750671,
      "learning_rate": 0.0002863803334275219,
      "loss": 8.784,
      "step": 1700
    },
    {
      "epoch": 2.818035426731079,
      "grad_norm": 0.6327773928642273,
      "learning_rate": 0.0002793161910144109,
      "loss": 8.8348,
      "step": 1750
    },
    {
      "epoch": 2.898550724637681,
      "grad_norm": 0.5360316634178162,
      "learning_rate": 0.0002722520486012998,
      "loss": 8.8662,
      "step": 1800
    },
    {
      "epoch": 2.9790660225442833,
      "grad_norm": 0.7289973497390747,
      "learning_rate": 0.0002651879061881888,
      "loss": 8.7166,
      "step": 1850
    },
    {
      "epoch": 3.0,
      "eval_bleu": 1.9486752362929625,
      "eval_loss": 8.800008773803711,
      "eval_runtime": 132.693,
      "eval_samples_per_second": 8.026,
      "eval_steps_per_second": 1.01,
      "step": 1863
    },
    {
      "epoch": 3.0595813204508855,
      "grad_norm": 0.8008045554161072,
      "learning_rate": 0.0002581237637750777,
      "loss": 8.858,
      "step": 1900
    },
    {
      "epoch": 3.140096618357488,
      "grad_norm": 1.3481322526931763,
      "learning_rate": 0.00025105962136196664,
      "loss": 8.8249,
      "step": 1950
    },
    {
      "epoch": 3.2206119162640903,
      "grad_norm": 0.7517961859703064,
      "learning_rate": 0.00024399547894885562,
      "loss": 8.7982,
      "step": 2000
    },
    {
      "epoch": 3.3011272141706924,
      "grad_norm": 0.7245256900787354,
      "learning_rate": 0.00023693133653574457,
      "loss": 8.7729,
      "step": 2050
    },
    {
      "epoch": 3.3816425120772946,
      "grad_norm": 0.7009937167167664,
      "learning_rate": 0.00022986719412263352,
      "loss": 8.8119,
      "step": 2100
    },
    {
      "epoch": 3.4621578099838968,
      "grad_norm": 0.8910828232765198,
      "learning_rate": 0.00022280305170952248,
      "loss": 8.7109,
      "step": 2150
    },
    {
      "epoch": 3.542673107890499,
      "grad_norm": 0.7260004281997681,
      "learning_rate": 0.0002157389092964114,
      "loss": 8.7483,
      "step": 2200
    },
    {
      "epoch": 3.6231884057971016,
      "grad_norm": 0.7181302309036255,
      "learning_rate": 0.00020867476688330035,
      "loss": 8.7312,
      "step": 2250
    },
    {
      "epoch": 3.7037037037037037,
      "grad_norm": 0.8436185717582703,
      "learning_rate": 0.00020161062447018933,
      "loss": 8.7678,
      "step": 2300
    },
    {
      "epoch": 3.784219001610306,
      "grad_norm": 0.6929934620857239,
      "learning_rate": 0.0001945464820570783,
      "loss": 8.8017,
      "step": 2350
    },
    {
      "epoch": 3.864734299516908,
      "grad_norm": 0.707331120967865,
      "learning_rate": 0.0001874823396439672,
      "loss": 8.7952,
      "step": 2400
    },
    {
      "epoch": 3.9452495974235102,
      "grad_norm": 0.9917275309562683,
      "learning_rate": 0.00018041819723085617,
      "loss": 8.7775,
      "step": 2450
    },
    {
      "epoch": 4.0,
      "eval_bleu": 2.5032386631777377,
      "eval_loss": 8.761102676391602,
      "eval_runtime": 132.1572,
      "eval_samples_per_second": 8.059,
      "eval_steps_per_second": 1.014,
      "step": 2484
    },
    {
      "epoch": 4.025764895330113,
      "grad_norm": 0.9032484292984009,
      "learning_rate": 0.00017335405481774515,
      "loss": 8.7059,
      "step": 2500
    },
    {
      "epoch": 4.106280193236715,
      "grad_norm": 0.8615729808807373,
      "learning_rate": 0.0001662899124046341,
      "loss": 8.6645,
      "step": 2550
    },
    {
      "epoch": 4.186795491143317,
      "grad_norm": 0.732505738735199,
      "learning_rate": 0.00015922576999152302,
      "loss": 8.6748,
      "step": 2600
    },
    {
      "epoch": 4.26731078904992,
      "grad_norm": 0.7717689275741577,
      "learning_rate": 0.00015216162757841198,
      "loss": 8.7229,
      "step": 2650
    },
    {
      "epoch": 4.3478260869565215,
      "grad_norm": 0.9482541680335999,
      "learning_rate": 0.00014509748516530093,
      "loss": 8.7527,
      "step": 2700
    },
    {
      "epoch": 4.428341384863124,
      "grad_norm": 1.0093649625778198,
      "learning_rate": 0.0001380333427521899,
      "loss": 8.7299,
      "step": 2750
    },
    {
      "epoch": 4.508856682769727,
      "grad_norm": 0.8671531081199646,
      "learning_rate": 0.00013096920033907884,
      "loss": 8.7431,
      "step": 2800
    },
    {
      "epoch": 4.5893719806763285,
      "grad_norm": 0.8169597387313843,
      "learning_rate": 0.0001239050579259678,
      "loss": 8.6815,
      "step": 2850
    },
    {
      "epoch": 4.669887278582931,
      "grad_norm": 1.0005220174789429,
      "learning_rate": 0.00011684091551285674,
      "loss": 8.7723,
      "step": 2900
    },
    {
      "epoch": 4.750402576489533,
      "grad_norm": 0.9289577007293701,
      "learning_rate": 0.0001097767730997457,
      "loss": 8.7191,
      "step": 2950
    },
    {
      "epoch": 4.830917874396135,
      "grad_norm": 0.7286153435707092,
      "learning_rate": 0.00010271263068663463,
      "loss": 8.7899,
      "step": 3000
    },
    {
      "epoch": 4.911433172302738,
      "grad_norm": 0.7955047488212585,
      "learning_rate": 9.56484882735236e-05,
      "loss": 8.7042,
      "step": 3050
    },
    {
      "epoch": 4.99194847020934,
      "grad_norm": 0.730037271976471,
      "learning_rate": 8.858434586041254e-05,
      "loss": 8.6809,
      "step": 3100
    },
    {
      "epoch": 5.0,
      "eval_bleu": 3.0688606056420555,
      "eval_loss": 8.732181549072266,
      "eval_runtime": 134.7206,
      "eval_samples_per_second": 7.905,
      "eval_steps_per_second": 0.995,
      "step": 3105
    },
    {
      "epoch": 5.072463768115942,
      "grad_norm": 0.5948876738548279,
      "learning_rate": 8.15202034473015e-05,
      "loss": 8.6843,
      "step": 3150
    },
    {
      "epoch": 5.152979066022544,
      "grad_norm": 0.7858298420906067,
      "learning_rate": 7.445606103419044e-05,
      "loss": 8.7318,
      "step": 3200
    },
    {
      "epoch": 5.233494363929147,
      "grad_norm": 0.7056021094322205,
      "learning_rate": 6.739191862107941e-05,
      "loss": 8.7118,
      "step": 3250
    },
    {
      "epoch": 5.314009661835748,
      "grad_norm": 0.844389021396637,
      "learning_rate": 6.032777620796835e-05,
      "loss": 8.5697,
      "step": 3300
    },
    {
      "epoch": 5.394524959742351,
      "grad_norm": 0.8570808172225952,
      "learning_rate": 5.32636337948573e-05,
      "loss": 8.7773,
      "step": 3350
    },
    {
      "epoch": 5.475040257648954,
      "grad_norm": 0.8825096487998962,
      "learning_rate": 4.6199491381746256e-05,
      "loss": 8.6077,
      "step": 3400
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 0.9724205136299133,
      "learning_rate": 3.913534896863521e-05,
      "loss": 8.5846,
      "step": 3450
    },
    {
      "epoch": 5.636070853462158,
      "grad_norm": 0.9082543849945068,
      "learning_rate": 3.207120655552416e-05,
      "loss": 8.6943,
      "step": 3500
    },
    {
      "epoch": 5.71658615136876,
      "grad_norm": 0.8585047721862793,
      "learning_rate": 2.500706414241311e-05,
      "loss": 8.6668,
      "step": 3550
    },
    {
      "epoch": 5.797101449275362,
      "grad_norm": 0.8957438468933105,
      "learning_rate": 1.7942921729302064e-05,
      "loss": 8.7199,
      "step": 3600
    },
    {
      "epoch": 5.877616747181965,
      "grad_norm": 0.9960392117500305,
      "learning_rate": 1.0878779316191015e-05,
      "loss": 8.7341,
      "step": 3650
    },
    {
      "epoch": 5.958132045088567,
      "grad_norm": 0.8777488470077515,
      "learning_rate": 3.8146369030799663e-06,
      "loss": 8.6839,
      "step": 3700
    },
    {
      "epoch": 6.0,
      "eval_bleu": 3.1997548023108404,
      "eval_loss": 8.725120544433594,
      "eval_runtime": 133.0345,
      "eval_samples_per_second": 8.005,
      "eval_steps_per_second": 1.007,
      "step": 3726
    }
  ],
  "logging_steps": 50,
  "max_steps": 3726,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "EarlyStoppingCallback": {
      "args": {
        "early_stopping_patience": 3,
        "early_stopping_threshold": 0.0
      },
      "attributes": {
        "early_stopping_patience_counter": 0
      }
    },
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 4063549791928320.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
