{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a890932b",
   "metadata": {},
   "source": [
    "cuda\n",
    "cpu\n",
    "Dispositivo: {device}\n",
    "PyTorch version: {torch.__version__}\n",
    "\n",
    "### Instala√ß√£o de Depend√™ncias\n",
    "Primeiro, garantimos que todas as bibliotecas necess√°rias estejam instaladas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c029e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dispositivo selecionado: cpu (tentando usar cuda)\n",
      "PyTorch version: 2.9.1+cpu\n",
      "GPU n√£o detectada no momento.\n",
      "  ‚Üí Se voc√™ tem uma GPU NVIDIA, confirme que os drivers/cuda est√£o instalados (execute `nvidia-smi`).\n",
      "  ‚Üí Instale a vers√£o CUDA do PyTorch: `pip install 'torch==2.9.1+cu118' --index-url https://download.pytorch.org/whl/cu118`.\n",
      "  ‚Üí Caso haja m√∫ltiplas GPUs, defina `CUDA_VISIBLE_DEVICES` antes de iniciar o notebook (por exemplo `CUDA_VISIBLE_DEVICES=0 jupyter lab`).\n"
     ]
    }
   ],
   "source": [
    "# Instala√ß√£o das depend√™ncias (executar apenas uma vez)\n",
    "# !pip install transformers datasets evaluate sacrebleu pandas openpyxl torch peft sentencepiece\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Imports principais\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Transformers e Datasets\n",
    "from transformers import (\n",
    "    MBart50TokenizerFast,\n",
    "    MBartForConditionalGeneration,\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "# Avalia√ß√£o\n",
    "import evaluate\n",
    "\n",
    "# PEFT para LoRA\n",
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "# Configura√ß√£o do dispositivo\n",
    "preferred_device = \"cuda\"\n",
    "device = torch.device(preferred_device if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Dispositivo selecionado: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "if device.type == \"cuda\":\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Mem√≥ria GPU: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è GPU n√£o detectada - o treinamento ser√° mais lento em CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6e2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configura√ß√µes carregadas:\n",
      "  model_checkpoint: facebook/mbart-large-50-many-to-many-mmt\n",
      "  max_input_length: 128\n",
      "  max_target_length: 128\n",
      "  learning_rate: 5e-05\n",
      "  batch_size: 4\n",
      "  num_epochs: 10\n",
      "  weight_decay: 0.01\n",
      "  warmup_steps: 100\n",
      "  early_stopping_patience: 3\n",
      "  lora_r: 16\n",
      "  lora_alpha: 32\n",
      "  lora_dropout: 0.05\n",
      "  data_path: ./data.xlsx\n",
      "  results_dir: ./results\n",
      "  models_dir: ./models\n",
      "  seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Configura√ß√µes globais do projeto\n",
    "CONFIG = {\n",
    "    # Modelos\n",
    "    \"model_checkpoint\": \"facebook/mbart-large-50-many-to-many-mmt\",  # Para fine-tuning\n",
    "    \"nllb_checkpoint\": \"facebook/nllb-200-distilled-600M\",  # Para zero-shot (tem Guarani!)\n",
    "    \n",
    "    # Tokeniza√ß√£o\n",
    "    \"max_input_length\": 128,\n",
    "    \"max_target_length\": 128,\n",
    "    \n",
    "    # Treinamento (otimizado para LoRA com mBART)\n",
    "    \"learning_rate\": 3e-5,\n",
    "    \"batch_size\": 4,\n",
    "    \"num_epochs\": 15,\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"warmup_ratio\": 0.1,\n",
    "    \n",
    "    # Early stopping\n",
    "    \"early_stopping_patience\": 5,\n",
    "    \n",
    "    # LoRA (Low-Rank Adaptation)\n",
    "    \"lora_r\": 32,\n",
    "    \"lora_alpha\": 64,\n",
    "    \"lora_dropout\": 0.1,\n",
    "    \n",
    "    # Caminhos\n",
    "    \"data_path\": \"./data.xlsx\",\n",
    "    \"results_dir\": \"./results\",\n",
    "    \"models_dir\": \"./models\",\n",
    "    \n",
    "    # Seed para reprodutibilidade\n",
    "    \"seed\": 42\n",
    "}\n",
    "\n",
    "# Criar diret√≥rios\n",
    "os.makedirs(CONFIG[\"results_dir\"], exist_ok=True)\n",
    "os.makedirs(CONFIG[\"models_dir\"], exist_ok=True)\n",
    "\n",
    "print(\"Configura√ß√µes carregadas:\")\n",
    "print(f\"\\nüì¶ Modelos:\")\n",
    "print(f\"  Zero-shot: {CONFIG['nllb_checkpoint']} (NLLB com Guarani)\")\n",
    "print(f\"  Fine-tune: {CONFIG['model_checkpoint']} (mBART-50)\")\n",
    "print(f\"\\n‚öôÔ∏è Hiperpar√¢metros de treinamento:\")\n",
    "print(f\"  Learning rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"  Batch size: {CONFIG['batch_size']}\")\n",
    "print(f\"  Epochs: {CONFIG['num_epochs']}\")\n",
    "print(f\"  LoRA rank: {CONFIG['lora_r']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d9f375",
   "metadata": {},
   "source": [
    "## 2. Justificativa do Modelo Escolhido\n",
    "\n",
    "### Por que mBART-50?\n",
    "\n",
    "Escolhemos o modelo **facebook/mbart-large-50-many-to-many-mmt** pelos seguintes motivos:\n",
    "\n",
    "1. **Arquitetura Encoder-Decoder**: O mBART utiliza a arquitetura Transformer completa (encoder-decoder), ideal para tarefas de tradu√ß√£o autom√°tica, diferente de modelos apenas decoder (GPT) ou apenas encoder (BERT).\n",
    "\n",
    "2. **Pr√©-treinamento Multil√≠ngue**: O modelo foi pr√©-treinado em 50 idiomas, incluindo o Portugu√™s. Embora n√£o inclua Tupi Antigo, o conhecimento multil√≠ngue pode ajudar na transfer√™ncia de padr√µes lingu√≠sticos.\n",
    "\n",
    "3. **Many-to-Many**: Esta variante permite tradu√ß√£o entre qualquer par de idiomas suportados, facilitando a adapta√ß√£o para novos pares lingu√≠sticos.\n",
    "\n",
    "4. **Suporte a L√≠nguas de Baixo Recurso**: O mBART foi projetado especificamente para cen√°rios de baixo recurso, onde h√° poucos dados de treinamento dispon√≠veis.\n",
    "\n",
    "5. **Fine-tuning Eficiente**: Com t√©cnicas como LoRA (Low-Rank Adaptation), podemos fazer fine-tuning eficiente mesmo com recursos computacionais limitados.\n",
    "\n",
    "### Alternativas Consideradas\n",
    "\n",
    "| Modelo | Pr√≥s | Contras |\n",
    "|--------|------|---------|\n",
    "| **mBART-50** | Multil√≠ngue, encoder-decoder, bom para baixo recurso | Grande (1.2GB), requer GPU |\n",
    "| **NLLB-200** | 200 idiomas, otimizado para tradu√ß√£o | Muito grande, pode ser lento |\n",
    "| **mT5** | Flex√≠vel, multil√≠ngue | N√£o espec√≠fico para tradu√ß√£o |\n",
    "| **T5** | Leve, r√°pido | Focado em ingl√™s |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab89da7c",
   "metadata": {},
   "source": [
    "## 3. Explica√ß√£o Matem√°tica das M√©tricas\n",
    "\n",
    "### 3.1 BLEU (Bilingual Evaluation Understudy)\n",
    "\n",
    "O BLEU mede a similaridade entre uma tradu√ß√£o candidata e uma ou mais tradu√ß√µes de refer√™ncia usando n-gramas.\n",
    "\n",
    "**F√≥rmula:**\n",
    "\n",
    "$$\\text{BLEU} = BP \\cdot \\exp\\left(\\sum_{n=1}^{N} w_n \\log p_n\\right)$$\n",
    "\n",
    "Onde:\n",
    "- $p_n$ √© a precis√£o do n-grama: $p_n = \\frac{\\text{n-gramas correspondentes}}{\\text{total de n-gramas na candidata}}$\n",
    "- $w_n$ √© o peso para cada n-grama (geralmente $w_n = 1/N$)\n",
    "- $BP$ √© a penalidade de brevidade:\n",
    "\n",
    "$$BP = \\begin{cases} 1 & \\text{se } c > r \\\\ e^{1-r/c} & \\text{se } c \\leq r \\end{cases}$$\n",
    "\n",
    "Onde $c$ √© o comprimento da candidata e $r$ √© o comprimento da refer√™ncia.\n",
    "\n",
    "### 3.2 chrF (Character-level F-score)\n",
    "\n",
    "O chrF utiliza n-gramas de **caracteres** ao inv√©s de palavras, sendo mais robusto para l√≠nguas morfologicamente ricas.\n",
    "\n",
    "**F√≥rmula:**\n",
    "\n",
    "$$\\text{chrF}_\\beta = (1 + \\beta^2) \\cdot \\frac{\\text{chrP} \\cdot \\text{chrR}}{\\beta^2 \\cdot \\text{chrP} + \\text{chrR}}$$\n",
    "\n",
    "Onde:\n",
    "- $\\text{chrP}$ = Precis√£o de n-gramas de caracteres\n",
    "- $\\text{chrR}$ = Recall de n-gramas de caracteres\n",
    "- $\\beta$ = Peso do recall (chrF1: $\\beta=1$, chrF3: $\\beta=3$)\n",
    "\n",
    "**chrF1** ($\\beta=1$): D√° peso igual para precis√£o e recall.\n",
    "\n",
    "**chrF3** ($\\beta=3$): D√° mais peso ao recall, √∫til quando queremos capturar mais do conte√∫do da refer√™ncia.\n",
    "\n",
    "### Por que chrF √© importante para Tupi Antigo?\n",
    "\n",
    "O Tupi Antigo possui morfologia complexa com prefixos, sufixos e varia√ß√µes ortogr√°ficas hist√≥ricas. M√©tricas baseadas em caracteres capturam melhor essas nuances do que m√©tricas baseadas em palavras.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a1f64a",
   "metadata": {},
   "source": [
    "## 4. Carregamento e Prepara√ß√£o dos Dados\n",
    "\n",
    "### 4.1 Leitura do Corpus\n",
    "\n",
    "O corpus paralelo Portugu√™s ‚Üî Tupi Antigo est√° armazenado em `data.xlsx` com as colunas:\n",
    "- **Portugu√™s**: Frases em portugu√™s\n",
    "- **Tupi Antigo**: Tradu√ß√µes correspondentes em Tupi Antigo\n",
    "\n",
    "**Importante**: Preservamos acentos, diacr√≠ticos e grafia hist√≥rica do Tupi Antigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "031e902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus carregado: 7097 pares de frases\n",
      "\n",
      "Colunas: ['Portugu√™s', 'Tupi Antigo']\n",
      "\n",
      "Primeiras 5 linhas:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Portugu√™s</th>\n",
       "      <th>Tupi Antigo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aparei as pontas deles</td>\n",
       "      <td>A√Æapyr-etab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doravante assim procedo</td>\n",
       "      <td>Ko'yr√© emon√£ a√Æk√≥</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As doen√ßas da alma do homem com ele saram bem</td>\n",
       "      <td>Ab√° 'anga mara'ara i pup√© op√ªe√Ær√°-katu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>√â discreta, falando aos homens</td>\n",
       "      <td>I kunus√£√Æ ab√° sup√© onhe'enga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Para se vingar de seu c√£o que cria, um homem n...</td>\n",
       "      <td>O e√Æmbaba √Æag√ªara res√© o√Æepyka, ab√° n'o√Æmomba'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Portugu√™s  \\\n",
       "0                             Aparei as pontas deles   \n",
       "1                            Doravante assim procedo   \n",
       "2      As doen√ßas da alma do homem com ele saram bem   \n",
       "3                     √â discreta, falando aos homens   \n",
       "4  Para se vingar de seu c√£o que cria, um homem n...   \n",
       "\n",
       "                                         Tupi Antigo  \n",
       "0                                        A√Æapyr-etab  \n",
       "1                                  Ko'yr√© emon√£ a√Æk√≥  \n",
       "2             Ab√° 'anga mara'ara i pup√© op√ªe√Ær√°-katu  \n",
       "3                       I kunus√£√Æ ab√° sup√© onhe'enga  \n",
       "4  O e√Æmbaba √Æag√ªara res√© o√Æepyka, ab√° n'o√Æmomba'...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Leitura do corpus\n",
    "df = pd.read_excel(CONFIG[\"data_path\"])\n",
    "\n",
    "# Normalizar nomes das colunas (corrige encoding Portugu√äs -> Portugu√™s)\n",
    "df.columns = df.columns.str.replace('Portugu√äs', 'Portugu√™s', regex=False)\n",
    "\n",
    "print(f\"Corpus carregado: {len(df)} pares de frases\")\n",
    "print(f\"\\nColunas: {list(df.columns)}\")\n",
    "print(f\"\\nPrimeiras 5 linhas:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f8a8a5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Informa√ß√µes do DataFrame:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7097 entries, 0 to 7096\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Portugu√™s    7097 non-null   object\n",
      " 1   Tupi Antigo  7097 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 111.0+ KB\n",
      "None\n",
      "\n",
      "Valores nulos:\n",
      "Portugu√™s      0\n",
      "Tupi Antigo    0\n",
      "dtype: int64\n",
      "\n",
      "Estat√≠sticas de comprimento (caracteres):\n",
      "            len_pt       len_ta\n",
      "count  7097.000000  7097.000000\n",
      "mean     35.728054    26.222911\n",
      "std      21.140072    17.144765\n",
      "min       3.000000     2.000000\n",
      "25%      20.000000    13.000000\n",
      "50%      31.000000    21.000000\n",
      "75%      47.000000    36.000000\n",
      "max     187.000000   136.000000\n"
     ]
    }
   ],
   "source": [
    "# Verificar informa√ß√µes do dataset\n",
    "print(\"Informa√ß√µes do DataFrame:\")\n",
    "print(df.info())\n",
    "print(f\"\\nValores nulos:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nEstat√≠sticas de comprimento (caracteres):\")\n",
    "df['len_pt'] = df['Portugu√™s'].astype(str).str.len()\n",
    "df['len_ta'] = df['Tupi Antigo'].astype(str).str.len()\n",
    "print(df[['len_pt', 'len_ta']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af7ec89",
   "metadata": {},
   "source": [
    "### 4.2 Limpeza e Normaliza√ß√£o\n",
    "\n",
    "Realizamos limpeza dos dados conforme orienta√ß√£o do professor:\n",
    "\n",
    "#### Texto em Portugu√™s:\n",
    "1. **Remo√ß√£o de express√µes entre par√™nteses**: O corpus cont√©m anota√ß√µes explicativas entre par√™nteses que n√£o aparecem na tradu√ß√£o Tupi\n",
    "   - Exemplo: `\"Desatei a boca dele (isto √©, do cavalo)\"` ‚Üí `\"Desatei a boca dele\"`\n",
    "2. **Remo√ß√£o de espa√ßos extras** (in√≠cio, fim, m√∫ltiplos espa√ßos)\n",
    "3. **Remo√ß√£o de caracteres invis√≠veis** (zero-width spaces, etc.)\n",
    "\n",
    "#### Texto em Tupi Antigo:\n",
    "1. **Apenas limpeza b√°sica** - preservamos acentos, diacr√≠ticos e grafia hist√≥rica\n",
    "2. **N√ÉO removemos**: acentos, diacr√≠ticos, mai√∫sculas/min√∫sculas\n",
    "\n",
    "**Justificativa**: O Tupi Antigo possui varia√ß√µes ortogr√°ficas hist√≥ricas e s√≠mbolos especiais que carregam significado lingu√≠stico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453d6f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ap√≥s limpeza: 7097 pares de frases\n",
      "\n",
      "Exemplos ap√≥s limpeza:\n",
      "\n",
      "[1] PT: Aparei as pontas deles\n",
      "    TA: A√Æapyr-etab\n",
      "\n",
      "[2] PT: Doravante assim procedo\n",
      "    TA: Ko'yr√© emon√£ a√Æk√≥\n",
      "\n",
      "[3] PT: As doen√ßas da alma do homem com ele saram bem\n",
      "    TA: Ab√° 'anga mara'ara i pup√© op√ªe√Ær√°-katu\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Limpeza b√°sica do texto, preservando acentos e diacr√≠ticos.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    text = str(text)\n",
    "    \n",
    "    # Remover caracteres invis√≠veis (zero-width spaces, etc.)\n",
    "    text = re.sub(r'[\\u200b\\u200c\\u200d\\ufeff]', '', text)\n",
    "    \n",
    "    # Remover espa√ßos extras (m√∫ltiplos espa√ßos -> um espa√ßo)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    \n",
    "    # Remover espa√ßos no in√≠cio e fim\n",
    "    text = text.strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "def clean_portuguese_text(text):\n",
    "    \"\"\"\n",
    "    Limpeza espec√≠fica do texto em Portugu√™s.\n",
    "    Remove express√µes entre par√™nteses conforme orienta√ß√£o do professor.\n",
    "    Ex: \"Desatei a boca dele (isto √©, do cavalo)\" -> \"Desatei a boca dele\"\n",
    "    \"\"\"\n",
    "    text = clean_text(text)\n",
    "    \n",
    "    # Remover express√µes entre par√™nteses (inclusive os par√™nteses)\n",
    "    text = re.sub(r'\\s*\\([^)]*\\)\\s*', ' ', text)\n",
    "    \n",
    "    # Limpar espa√ßos extras resultantes\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    \n",
    "    # Remover v√≠rgulas duplicadas ou soltas\n",
    "    text = re.sub(r',\\s*,', ',', text)\n",
    "    text = re.sub(r',\\s*$', '', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "# Aplicar limpeza\n",
    "# Portugu√™s: remover express√µes entre par√™nteses\n",
    "df['Portugu√™s'] = df['Portugu√™s'].apply(clean_portuguese_text)\n",
    "# Tupi Antigo: apenas limpeza b√°sica (preservar grafia hist√≥rica)\n",
    "df['Tupi Antigo'] = df['Tupi Antigo'].apply(clean_text)\n",
    "\n",
    "# Remover linhas vazias\n",
    "df = df[(df['Portugu√™s'] != '') & (df['Tupi Antigo'] != '')]\n",
    "\n",
    "# Remover colunas auxiliares de comprimento\n",
    "df = df.drop(columns=['len_pt', 'len_ta'], errors='ignore')\n",
    "\n",
    "print(f\"Ap√≥s limpeza: {len(df)} pares de frases\")\n",
    "print(\"\\nExemplos ap√≥s limpeza (note remo√ß√£o de par√™nteses no PT):\")\n",
    "for i in range(min(5, len(df))):\n",
    "    print(f\"\\n[{i+1}] PT: {df.iloc[i]['Portugu√™s']}\")\n",
    "    print(f\"    TA: {df.iloc[i]['Tupi Antigo']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef89123c",
   "metadata": {},
   "source": [
    "### 4.3 Divis√£o do Corpus\n",
    "\n",
    "Dividimos o corpus em tr√™s conjuntos:\n",
    "- **Treino (70%)**: Para fine-tuning do modelo\n",
    "- **Valida√ß√£o (15%)**: Para early stopping e sele√ß√£o de hiperpar√¢metros\n",
    "- **Teste (15%)**: Para avalia√ß√£o final (nunca usado durante treinamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c8f07d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Divis√£o do corpus:\n",
      "  Treino:     4967 (70.0%)\n",
      "  Valida√ß√£o:  1065 (15.0%)\n",
      "  Teste:      1065 (15.0%)\n",
      "  Total:      7097\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Definir seed para reprodutibilidade\n",
    "np.random.seed(CONFIG[\"seed\"])\n",
    "\n",
    "# Primeira divis√£o: 70% treino, 30% (valida√ß√£o + teste)\n",
    "train_df, temp_df = train_test_split(df, test_size=0.30, random_state=CONFIG[\"seed\"])\n",
    "\n",
    "# Segunda divis√£o: 50% valida√ß√£o, 50% teste (do temp_df)\n",
    "# Isso resulta em 15% valida√ß√£o e 15% teste do total\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.50, random_state=CONFIG[\"seed\"])\n",
    "\n",
    "print(f\"Divis√£o do corpus:\")\n",
    "print(f\"  Treino:     {len(train_df)} ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Valida√ß√£o:  {len(val_df)} ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Teste:      {len(test_df)} ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Total:      {len(df)}\")\n",
    "\n",
    "# Reset dos √≠ndices\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eb83f44b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subconjuntos salvos em ./data/\n",
      "  train.csv: 4967 exemplos\n",
      "  val.csv:   1065 exemplos\n",
      "  test.csv:  1065 exemplos\n"
     ]
    }
   ],
   "source": [
    "# Salvar os subconjuntos para uso posterior\n",
    "os.makedirs(\"./data\", exist_ok=True)\n",
    "\n",
    "train_df.to_csv(\"./data/train.csv\", index=False)\n",
    "val_df.to_csv(\"./data/val.csv\", index=False)\n",
    "test_df.to_csv(\"./data/test.csv\", index=False)\n",
    "\n",
    "print(\"Subconjuntos salvos em ./data/\")\n",
    "print(f\"  train.csv: {len(train_df)} exemplos\")\n",
    "print(f\"  val.csv:   {len(val_df)} exemplos\")\n",
    "print(f\"  test.csv:  {len(test_df)} exemplos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97f54234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Hugging Face criado:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['portuguese', 'tupi'],\n",
      "        num_rows: 4967\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['portuguese', 'tupi'],\n",
      "        num_rows: 1065\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['portuguese', 'tupi'],\n",
      "        num_rows: 1065\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "# Converter para Datasets do Hugging Face\n",
    "def df_to_dataset(df):\n",
    "    \"\"\"Converte DataFrame para Dataset do Hugging Face.\"\"\"\n",
    "    return Dataset.from_dict({\n",
    "        \"portuguese\": df[\"Portugu√™s\"].tolist(),\n",
    "        \"tupi\": df[\"Tupi Antigo\"].tolist()\n",
    "    })\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    \"train\": df_to_dataset(train_df),\n",
    "    \"validation\": df_to_dataset(val_df),\n",
    "    \"test\": df_to_dataset(test_df)\n",
    "})\n",
    "\n",
    "print(\"Dataset Hugging Face criado:\")\n",
    "print(dataset_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3140e7a",
   "metadata": {},
   "source": [
    "## 5. Configura√ß√£o do Modelo e Tokenizador\n",
    "\n",
    "### Tratamento do Tupi Antigo no mBART\n",
    "\n",
    "O mBART n√£o possui c√≥digo de idioma nativo para Tupi Antigo. Utilizamos uma estrat√©gia de adapta√ß√£o:\n",
    "\n",
    "1. Usamos o c√≥digo de idioma do Portugu√™s (`pt_XX`) como proxy para ambos os idiomas\n",
    "2. Adicionamos prefixos textuais nas entradas para indicar a dire√ß√£o da tradu√ß√£o\n",
    "3. O modelo aprende a associar esses padr√µes durante o fine-tuning\n",
    "\n",
    "**Nota**: Esta √© uma limita√ß√£o do cen√°rio de baixo recurso. Em um cen√°rio ideal, ter√≠amos um tokenizador e c√≥digo de idioma espec√≠fico para Tupi Antigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a918f17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da84e6cb07634eb884e4ada704e332cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da84e6cb07634eb884e4ada704e332cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e220005b084e58947bb963d27a0c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da84e6cb07634eb884e4ada704e332cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e220005b084e58947bb963d27a0c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b00e101abd46fbada0be7e18b37167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da84e6cb07634eb884e4ada704e332cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e220005b084e58947bb963d27a0c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b00e101abd46fbada0be7e18b37167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca064c166864ba49b9874740ccb91d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da84e6cb07634eb884e4ada704e332cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/529 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07e220005b084e58947bb963d27a0c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b00e101abd46fbada0be7e18b37167",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/649 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca064c166864ba49b9874740ccb91d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizador carregado: facebook/mbart-large-50-many-to-many-mmt\n",
      "Vocabul√°rio: 250054 tokens\n",
      "C√≥digo de idioma usado: pt_XX\n"
     ]
    }
   ],
   "source": [
    "# Carregar tokenizador\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(CONFIG[\"model_checkpoint\"])\n",
    "\n",
    "# Configura√ß√£o de idiomas\n",
    "# Usamos pt_XX como proxy para ambos (PT e Tupi Antigo)\n",
    "# O modelo aprender√° a distin√ß√£o atrav√©s dos prefixos e do fine-tuning\n",
    "LANG_CODE = \"pt_XX\"\n",
    "\n",
    "# Prefixos para indicar dire√ß√£o da tradu√ß√£o\n",
    "# Isso ajuda o modelo a distinguir as tarefas durante o fine-tuning\n",
    "PREFIX_PT_TO_TA = \"traduzir para tupi: \"\n",
    "PREFIX_TA_TO_PT = \"traduzir para portugu√™s: \"\n",
    "\n",
    "print(f\"Tokenizador carregado: {CONFIG['model_checkpoint']}\")\n",
    "print(f\"Vocabul√°rio: {tokenizer.vocab_size} tokens\")\n",
    "print(f\"C√≥digo de idioma: {LANG_CODE}\")\n",
    "print(f\"Prefixo PT‚ÜíTA: '{PREFIX_PT_TO_TA}'\")\n",
    "print(f\"Prefixo TA‚ÜíPT: '{PREFIX_TA_TO_PT}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6528a2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√µes de pr√©-processamento para cada dire√ß√£o de tradu√ß√£o\n",
    "\n",
    "def preprocess_pt_to_ta(examples):\n",
    "    \"\"\"Pr√©-processa para tradu√ß√£o Portugu√™s -> Tupi Antigo.\"\"\"\n",
    "    inputs = examples[\"portuguese\"]\n",
    "    targets = examples[\"tupi\"]\n",
    "    \n",
    "    tokenizer.src_lang = LANG_CODE\n",
    "    tokenizer.tgt_lang = LANG_CODE\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=CONFIG[\"max_input_length\"], \n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        text_target=targets,\n",
    "        max_length=CONFIG[\"max_target_length\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "def preprocess_ta_to_pt(examples):\n",
    "    \"\"\"Pr√©-processa para tradu√ß√£o Tupi Antigo -> Portugu√™s.\"\"\"\n",
    "    inputs = examples[\"tupi\"]\n",
    "    targets = examples[\"portuguese\"]\n",
    "    \n",
    "    tokenizer.src_lang = LANG_CODE\n",
    "    tokenizer.tgt_lang = LANG_CODE\n",
    "    \n",
    "    model_inputs = tokenizer(\n",
    "        inputs, \n",
    "        max_length=CONFIG[\"max_input_length\"], \n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    labels = tokenizer(\n",
    "        text_target=targets,\n",
    "        max_length=CONFIG[\"max_target_length\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "print(\"Fun√ß√µes de pr√©-processamento definidas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c99a9",
   "metadata": {},
   "source": [
    "## 6. Configura√ß√£o das M√©tricas de Avalia√ß√£o\n",
    "\n",
    "Implementamos as m√©tricas conforme especificado no enunciado:\n",
    "- **BLEU**: Usando SacreBLEU para resultados reproduz√≠veis\n",
    "- **chrF1**: F-score de caracteres com Œ≤=1\n",
    "- **chrF3**: F-score de caracteres com Œ≤=3 (mais peso no recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66d21a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar m√©tricas\n",
    "bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "chrf_metric = evaluate.load(\"chrf\")\n",
    "\n",
    "def compute_all_metrics(predictions, references):\n",
    "    \"\"\"\n",
    "    Calcula todas as m√©tricas de avalia√ß√£o.\n",
    "    \n",
    "    Args:\n",
    "        predictions: Lista de tradu√ß√µes geradas\n",
    "        references: Lista de tradu√ß√µes de refer√™ncia\n",
    "        \n",
    "    Returns:\n",
    "        Dicion√°rio com todas as m√©tricas\n",
    "    \"\"\"\n",
    "    # BLEU espera refer√™ncias como lista de listas\n",
    "    refs_for_bleu = [[ref] for ref in references]\n",
    "    \n",
    "    # BLEU\n",
    "    bleu_result = bleu_metric.compute(predictions=predictions, references=refs_for_bleu)\n",
    "    \n",
    "    # chrF1 (beta=1)\n",
    "    chrf1_result = chrf_metric.compute(\n",
    "        predictions=predictions, \n",
    "        references=refs_for_bleu,\n",
    "        char_order=6,\n",
    "        word_order=0,\n",
    "        beta=1\n",
    "    )\n",
    "    \n",
    "    # chrF3 (beta=3)\n",
    "    chrf3_result = chrf_metric.compute(\n",
    "        predictions=predictions, \n",
    "        references=refs_for_bleu,\n",
    "        char_order=6,\n",
    "        word_order=0,\n",
    "        beta=3\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"bleu\": bleu_result[\"score\"],\n",
    "        \"chrf1\": chrf1_result[\"score\"],\n",
    "        \"chrf3\": chrf3_result[\"score\"],\n",
    "        \"bleu_details\": {\n",
    "            \"precisions\": bleu_result[\"precisions\"],\n",
    "            \"brevity_penalty\": bleu_result[\"bp\"],\n",
    "            \"length_ratio\": bleu_result[\"sys_len\"] / bleu_result[\"ref_len\"] if bleu_result[\"ref_len\"] > 0 else 0\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"M√©tricas carregadas e configuradas:\")\n",
    "print(\"  - BLEU (SacreBLEU)\")\n",
    "print(\"  - chrF1 (Œ≤=1)\")\n",
    "print(\"  - chrF3 (Œ≤=3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e82aa9",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Tradu√ß√£o Zero-Shot\n",
    "\n",
    "No regime **zero-shot**, utilizamos o modelo pr√©-treinado diretamente, sem qualquer fine-tuning no corpus Portugu√™s-Tupi Antigo.\n",
    "\n",
    "### Estrat√©gia: Usar NLLB com Guarani como Proxy\n",
    "\n",
    "Conforme orienta√ß√£o do professor:\n",
    "- O **mBART com pt‚Üípt** produz tradu√ß√£o quase nula no zero-shot\n",
    "- O modelo **NLLB-200** possui suporte ao **Guarani** (`grn_Latn`), l√≠ngua da fam√≠lia Tupi-Guarani relacionada ao Tupi Antigo\n",
    "- Usamos Guarani como l√≠ngua proxy para aproximar o Tupi Antigo\n",
    "\n",
    "### Transforma√ß√£o Guarani ‚Üí Tupi Antigo\n",
    "\n",
    "Para melhorar a correspond√™ncia entre a sa√≠da do modelo (Guarani) e o Tupi Antigo de refer√™ncia, aplicamos transforma√ß√µes b√°sicas conforme sugerido pelo professor:\n",
    "- `√±` ‚Üí `nh` (nasaliza√ß√£o)\n",
    "\n",
    "**Modelo**: `facebook/nllb-200-distilled-600M` (vers√£o leve do NLLB-200)\n",
    "\n",
    "**C√≥digos de idioma NLLB**:\n",
    "- Portugu√™s: `por_Latn`\n",
    "- Guarani: `grn_Latn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fb78c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo NLLB para zero-shot (tem suporte a Guarani!)\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "NLLB_CHECKPOINT = \"facebook/nllb-200-distilled-600M\"\n",
    "\n",
    "print(\"Carregando modelo NLLB-200 para zero-shot...\")\n",
    "print(\"(NLLB possui Guarani - l√≠ngua da fam√≠lia Tupi-Guarani)\")\n",
    "\n",
    "tokenizer_nllb = AutoTokenizer.from_pretrained(NLLB_CHECKPOINT)\n",
    "model_zero_shot = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    NLLB_CHECKPOINT,\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "model_zero_shot = model_zero_shot.to(device)\n",
    "model_zero_shot.eval()\n",
    "\n",
    "# C√≥digos de idioma NLLB\n",
    "LANG_PT_NLLB = \"por_Latn\"   # Portugu√™s\n",
    "LANG_GN_NLLB = \"grn_Latn\"   # Guarani (proxy para Tupi Antigo)\n",
    "\n",
    "print(f\"\\nModelo carregado: {NLLB_CHECKPOINT}\")\n",
    "print(f\"Par√¢metros: {sum(p.numel() for p in model_zero_shot.parameters()):,}\")\n",
    "print(f\"\\nIdiomas para zero-shot:\")\n",
    "print(f\"  Portugu√™s: {LANG_PT_NLLB}\")\n",
    "print(f\"  Guarani (proxy Tupi): {LANG_GN_NLLB}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd27d6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o de tradu√ß√£o para NLLB (zero-shot)\n",
    "def translate_batch_nllb(model, tokenizer, texts, source_lang, target_lang, batch_size=8, \n",
    "                          num_beams=5, max_length=128):\n",
    "    \"\"\"\n",
    "    Traduz um lote de textos usando o modelo NLLB.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    translations = []\n",
    "    \n",
    "    tokenizer.src_lang = source_lang\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            batch, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True,\n",
    "            max_length=max_length\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated = model.generate(\n",
    "                **inputs,\n",
    "                forced_bos_token_id=tokenizer.convert_tokens_to_ids(target_lang),\n",
    "                max_length=max_length,\n",
    "                num_beams=num_beams,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        decoded = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
    "        translations.extend(decoded)\n",
    "        \n",
    "        if (i // batch_size + 1) % 20 == 0:\n",
    "            print(f\"  Traduzidos: {min(i + batch_size, len(texts))}/{len(texts)}\")\n",
    "    \n",
    "    return translations\n",
    "\n",
    "def guarani_to_tupi_transform(text):\n",
    "    \"\"\"\n",
    "    Aplica transforma√ß√µes b√°sicas do Guarani para aproximar o Tupi Antigo.\n",
    "    Conforme orienta√ß√£o do professor: '√±' -> 'nh'\n",
    "    \"\"\"\n",
    "    # Transforma√ß√£o principal sugerida pelo professor\n",
    "    text = text.replace('√±', 'nh')\n",
    "    text = text.replace('√ë', 'Nh')\n",
    "    return text\n",
    "\n",
    "print(\"Fun√ß√µes de tradu√ß√£o NLLB e transforma√ß√£o Guarani‚ÜíTupi definidas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c9266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o de tradu√ß√£o padr√£o com mBART (usada no fine-tuning)\n",
    "def translate_batch(model, texts, source_lang, target_lang, batch_size=8):\n",
    "    \"\"\"\n",
    "    Traduz um lote de textos usando o modelo mBART.\n",
    "    Usada para avalia√ß√£o dos modelos fine-tuned.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    translations = []\n",
    "    \n",
    "    tokenizer.src_lang = source_lang\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i+batch_size]\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            batch, \n",
    "            return_tensors=\"pt\", \n",
    "            padding=True, \n",
    "            truncation=True,\n",
    "            max_length=CONFIG[\"max_input_length\"]\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            generated = model.generate(\n",
    "                **inputs,\n",
    "                forced_bos_token_id=tokenizer.lang_code_to_id[target_lang],\n",
    "                max_length=CONFIG[\"max_target_length\"],\n",
    "                num_beams=5,\n",
    "                early_stopping=True\n",
    "            )\n",
    "        \n",
    "        decoded = tokenizer.batch_decode(generated, skip_special_tokens=True)\n",
    "        translations.extend(decoded)\n",
    "        \n",
    "        if (i // batch_size + 1) % 10 == 0:\n",
    "            print(f\"  Traduzidos: {min(i + batch_size, len(texts))}/{len(texts)}\")\n",
    "    \n",
    "    return translations\n",
    "\n",
    "print(\"Fun√ß√£o de tradu√ß√£o mBART definida (para fine-tuning).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5cc0b3",
   "metadata": {},
   "source": [
    "### 7.1 Zero-Shot: Portugu√™s ‚Üí Tupi Antigo (via Guarani)\n",
    "\n",
    "Traduzimos Portugu√™s ‚Üí Guarani usando NLLB, e depois aplicamos a transforma√ß√£o `√± ‚Üí nh` para aproximar do Tupi Antigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f3afe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados de teste\n",
    "test_portuguese = test_df[\"Portugu√™s\"].tolist()\n",
    "test_tupi_ref = test_df[\"Tupi Antigo\"].tolist()\n",
    "test_tupi = test_df[\"Tupi Antigo\"].tolist()\n",
    "test_portuguese_ref = test_df[\"Portugu√™s\"].tolist()\n",
    "\n",
    "print(f\"Conjunto de teste: {len(test_portuguese)} exemplos\")\n",
    "print(f\"\\nExemplos do corpus:\")\n",
    "for i in range(min(3, len(test_portuguese))):\n",
    "    print(f\"  PT: {test_portuguese[i][:60]}...\")\n",
    "    print(f\"  TA: {test_tupi_ref[i][:60]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ee9801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ZERO-SHOT: Portugu√™s ‚Üí Tupi Antigo (via NLLB + Guarani)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ZERO-SHOT: Portugu√™s ‚Üí Tupi Antigo (via NLLB + Guarani)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\nTraduzindo PT ‚Üí Guarani...\")\n",
    "translations_pt_gn = translate_batch_nllb(\n",
    "    model_zero_shot,\n",
    "    tokenizer_nllb,\n",
    "    test_portuguese,\n",
    "    source_lang=LANG_PT_NLLB,\n",
    "    target_lang=LANG_GN_NLLB,\n",
    "    num_beams=5,\n",
    "    max_length=CONFIG[\"max_target_length\"]\n",
    ")\n",
    "\n",
    "# Aplicar transforma√ß√£o Guarani ‚Üí Tupi Antigo (√± ‚Üí nh)\n",
    "print(\"Aplicando transforma√ß√£o Guarani ‚Üí Tupi Antigo (√± ‚Üí nh)...\")\n",
    "translations_pt_ta_zero = [guarani_to_tupi_transform(t) for t in translations_pt_gn]\n",
    "\n",
    "# Calcular m√©tricas\n",
    "metrics_pt_ta_zero = compute_all_metrics(translations_pt_ta_zero, test_tupi_ref)\n",
    "\n",
    "print(f\"\\nTraduzidas {len(translations_pt_ta_zero)} frases.\")\n",
    "print(\"\\n=== M√©tricas Zero-Shot PT ‚Üí TA (via Guarani) ===\")\n",
    "print(f\"  BLEU:  {metrics_pt_ta_zero['bleu']:.2f}\")\n",
    "print(f\"  chrF1: {metrics_pt_ta_zero['chrf1']:.2f}\")\n",
    "print(f\"  chrF3: {metrics_pt_ta_zero['chrf3']:.2f}\")\n",
    "\n",
    "# Mostrar alguns exemplos\n",
    "print(\"\\n--- Exemplos (PT ‚Üí Guarani ‚Üí Tupi aproximado) ---\")\n",
    "for i in range(min(3, len(test_portuguese))):\n",
    "    print(f\"\\n[{i+1}] Fonte PT:     {test_portuguese[i]}\")\n",
    "    print(f\"    Guarani:      {translations_pt_gn[i]}\")\n",
    "    print(f\"    Tupi (aprox): {translations_pt_ta_zero[i]}\")\n",
    "    print(f\"    Refer√™ncia:   {test_tupi_ref[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bbc75a",
   "metadata": {},
   "source": [
    "### 7.2 Zero-Shot: Tupi Antigo ‚Üí Portugu√™s (via Guarani)\n",
    "\n",
    "Para a dire√ß√£o inversa, tratamos o Tupi Antigo como se fosse Guarani. O NLLB tenta \"entender\" o texto Tupi usando seu conhecimento de Guarani e traduz para Portugu√™s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f38eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ZERO-SHOT: Tupi Antigo ‚Üí Portugu√™s (via NLLB + Guarani)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ZERO-SHOT: Tupi Antigo ‚Üí Portugu√™s (via NLLB + Guarani)\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Tratamos o Tupi Antigo como se fosse Guarani para o NLLB\n",
    "print(\"\\nTraduzindo Tupi (como Guarani) ‚Üí PT...\")\n",
    "translations_ta_pt_zero = translate_batch_nllb(\n",
    "    model_zero_shot,\n",
    "    tokenizer_nllb,\n",
    "    test_tupi,  # Tupi Antigo tratado como Guarani\n",
    "    source_lang=LANG_GN_NLLB,  # Guarani como proxy\n",
    "    target_lang=LANG_PT_NLLB,\n",
    "    num_beams=5,\n",
    "    max_length=CONFIG[\"max_target_length\"]\n",
    ")\n",
    "\n",
    "# Calcular m√©tricas\n",
    "metrics_ta_pt_zero = compute_all_metrics(translations_ta_pt_zero, test_portuguese_ref)\n",
    "\n",
    "print(f\"\\nTraduzidas {len(translations_ta_pt_zero)} frases.\")\n",
    "print(\"\\n=== M√©tricas Zero-Shot TA ‚Üí PT (via Guarani) ===\")\n",
    "print(f\"  BLEU:  {metrics_ta_pt_zero['bleu']:.2f}\")\n",
    "print(f\"  chrF1: {metrics_ta_pt_zero['chrf1']:.2f}\")\n",
    "print(f\"  chrF3: {metrics_ta_pt_zero['chrf3']:.2f}\")\n",
    "\n",
    "# Mostrar alguns exemplos\n",
    "print(\"\\n--- Exemplos (Tupi ‚Üí PT via Guarani) ---\")\n",
    "for i in range(min(3, len(test_tupi))):\n",
    "    print(f\"\\n[{i+1}] Fonte TA:   {test_tupi[i]}\")\n",
    "    print(f\"    Tradu√ß√£o:   {translations_ta_pt_zero[i]}\")\n",
    "    print(f\"    Refer√™ncia: {test_portuguese_ref[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3887f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# RESUMO ZERO-SHOT COM NLLB + GUARANI\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"RESUMO ZERO-SHOT: NLLB-200 com Guarani como Proxy para Tupi Antigo\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüìä M√©tricas Zero-Shot:\")\n",
    "print(f\"{'Dire√ß√£o':<20} {'BLEU':>10} {'chrF1':>10} {'chrF3':>10}\")\n",
    "print(\"-\" * 50)\n",
    "print(f\"{'PT ‚Üí TA (via GN)':<20} {metrics_pt_ta_zero['bleu']:>10.2f} {metrics_pt_ta_zero['chrf1']:>10.2f} {metrics_pt_ta_zero['chrf3']:>10.2f}\")\n",
    "print(f\"{'TA ‚Üí PT (via GN)':<20} {metrics_ta_pt_zero['bleu']:>10.2f} {metrics_ta_pt_zero['chrf1']:>10.2f} {metrics_ta_pt_zero['chrf3']:>10.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EXEMPLOS QUALITATIVOS ZERO-SHOT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "n_examples = min(5, len(test_portuguese))\n",
    "\n",
    "print(\"\\n--- PT ‚Üí TA (via Guarani) ---\")\n",
    "for i in range(n_examples):\n",
    "    print(f\"\\n[{i+1}] Fonte:      {test_portuguese[i]}\")\n",
    "    print(f\"    Refer√™ncia: {test_tupi_ref[i]}\")\n",
    "    print(f\"    Zero-Shot:  {translations_pt_ta_zero[i]}\")\n",
    "\n",
    "print(\"\\n--- TA ‚Üí PT (via Guarani) ---\")\n",
    "for i in range(n_examples):\n",
    "    print(f\"\\n[{i+1}] Fonte:      {test_tupi[i]}\")\n",
    "    print(f\"    Refer√™ncia: {test_portuguese_ref[i]}\")\n",
    "    print(f\"    Zero-Shot:  {translations_ta_pt_zero[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237517e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados zero-shot\n",
    "results_zero_shot = {\n",
    "    \"pt_to_ta\": {\n",
    "        \"bleu\": metrics_pt_ta_zero[\"bleu\"],\n",
    "        \"chrf1\": metrics_pt_ta_zero[\"chrf1\"],\n",
    "        \"chrf3\": metrics_pt_ta_zero[\"chrf3\"],\n",
    "        \"bleu_details\": metrics_pt_ta_zero[\"bleu_details\"]\n",
    "    },\n",
    "    \"ta_to_pt\": {\n",
    "        \"bleu\": metrics_ta_pt_zero[\"bleu\"],\n",
    "        \"chrf1\": metrics_ta_pt_zero[\"chrf1\"],\n",
    "        \"chrf3\": metrics_ta_pt_zero[\"chrf3\"],\n",
    "        \"bleu_details\": metrics_ta_pt_zero[\"bleu_details\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar em arquivo JSON\n",
    "with open(os.path.join(CONFIG[\"results_dir\"], \"results_zero_shot.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_zero_shot, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Resultados zero-shot salvos em results/results_zero_shot.json\")\n",
    "\n",
    "# Salvar tradu√ß√µes\n",
    "os.makedirs(os.path.join(CONFIG[\"results_dir\"], \"outputs_zero_shot\"), exist_ok=True)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"source\": test_portuguese,\n",
    "    \"reference\": test_tupi_ref,\n",
    "    \"translation\": translations_pt_ta_zero\n",
    "}).to_csv(os.path.join(CONFIG[\"results_dir\"], \"outputs_zero_shot\", \"pt_to_ta.csv\"), index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"source\": test_tupi,\n",
    "    \"reference\": test_portuguese_ref,\n",
    "    \"translation\": translations_ta_pt_zero\n",
    "}).to_csv(os.path.join(CONFIG[\"results_dir\"], \"outputs_zero_shot\", \"ta_to_pt.csv\"), index=False)\n",
    "\n",
    "print(\"Tradu√ß√µes salvas em results/outputs_zero_shot/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db067c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar mem√≥ria do modelo zero-shot\n",
    "del model_zero_shot\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "print(\"Mem√≥ria liberada.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c740bd99",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Fine-Tuning (Few-Shot Learning)\n",
    "\n",
    "No regime **few-shot**, realizamos o ajuste fino (fine-tuning) do modelo mBART usando o corpus de treinamento.\n",
    "\n",
    "### Estrat√©gia de Treinamento\n",
    "\n",
    "1. **LoRA (Low-Rank Adaptation)**: Utilizamos LoRA para reduzir o n√∫mero de par√¢metros trein√°veis, tornando o fine-tuning mais eficiente\n",
    "2. **Early Stopping**: Interrompemos o treinamento quando a perda de valida√ß√£o para de melhorar\n",
    "3. **Duas dire√ß√µes**: Treinamos modelos separados para PT‚ÜíTA e TA‚ÜíPT\n",
    "\n",
    "### Hiperpar√¢metros\n",
    "- Learning rate: 5e-5\n",
    "- Batch size: 4\n",
    "- Early stopping patience: 3 epochs\n",
    "- LoRA rank: 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4740457",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trainer(model, tokenizer, train_dataset, val_dataset, output_dir, direction):\n",
    "    \"\"\"\n",
    "    Cria um Seq2SeqTrainer configurado para o fine-tuning.\n",
    "    \"\"\"\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
    "    \n",
    "    def compute_metrics_trainer(eval_preds):\n",
    "        preds, labels = eval_preds\n",
    "        \n",
    "        if isinstance(preds, tuple):\n",
    "            preds = preds[0]\n",
    "        \n",
    "        decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "        \n",
    "        labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "        decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        \n",
    "        refs = [[l] for l in decoded_labels]\n",
    "        bleu_result = bleu_metric.compute(predictions=decoded_preds, references=refs)\n",
    "        \n",
    "        return {\"bleu\": bleu_result[\"score\"]}\n",
    "    \n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        learning_rate=CONFIG[\"learning_rate\"],\n",
    "        per_device_train_batch_size=CONFIG[\"batch_size\"],\n",
    "        per_device_eval_batch_size=CONFIG[\"batch_size\"],\n",
    "        num_train_epochs=CONFIG[\"num_epochs\"],\n",
    "        weight_decay=CONFIG[\"weight_decay\"],\n",
    "        warmup_ratio=CONFIG[\"warmup_ratio\"],\n",
    "        eval_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"bleu\",\n",
    "        greater_is_better=True,\n",
    "        predict_with_generate=True,\n",
    "        generation_max_length=CONFIG[\"max_target_length\"],\n",
    "        fp16=torch.cuda.is_available(),\n",
    "        logging_dir=f\"{output_dir}/logs\",\n",
    "        logging_steps=50,\n",
    "        save_total_limit=2,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    \n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        processing_class=tokenizer,\n",
    "        data_collator=data_collator,\n",
    "        compute_metrics=compute_metrics_trainer,\n",
    "        callbacks=[EarlyStoppingCallback(early_stopping_patience=CONFIG[\"early_stopping_patience\"])]\n",
    "    )\n",
    "    \n",
    "    return trainer\n",
    "\n",
    "print(\"Fun√ß√£o de cria√ß√£o do trainer definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0509dd62",
   "metadata": {},
   "source": [
    "### 8.1 Fine-Tuning: Portugu√™s ‚Üí Tupi Antigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f704e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizar datasets para PT -> TA\n",
    "print(\"Tokenizando datasets para PT ‚Üí TA...\")\n",
    "tokenized_train_pt_ta = dataset_dict[\"train\"].map(preprocess_pt_to_ta, batched=True)\n",
    "tokenized_val_pt_ta = dataset_dict[\"validation\"].map(preprocess_pt_to_ta, batched=True)\n",
    "\n",
    "print(f\"Treino: {len(tokenized_train_pt_ta)} exemplos\")\n",
    "print(f\"Valida√ß√£o: {len(tokenized_val_pt_ta)} exemplos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo base para PT -> TA\n",
    "print(\"Carregando modelo base para fine-tuning PT ‚Üí TA...\")\n",
    "model_pt_ta = MBartForConditionalGeneration.from_pretrained(\n",
    "    CONFIG[\"model_checkpoint\"],\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "\n",
    "# Aplicar LoRA\n",
    "lora_config = LoraConfig(\n",
    "    r=CONFIG[\"lora_r\"],\n",
    "    lora_alpha=CONFIG[\"lora_alpha\"],\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],\n",
    "    lora_dropout=CONFIG[\"lora_dropout\"],\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")\n",
    "\n",
    "model_pt_ta = get_peft_model(model_pt_ta, lora_config)\n",
    "model_pt_ta.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628dd702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo PT -> TA\n",
    "print(\"Iniciando treinamento PT ‚Üí TA...\")\n",
    "trainer_pt_ta = create_trainer(\n",
    "    model=model_pt_ta,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_train_pt_ta,\n",
    "    val_dataset=tokenized_val_pt_ta,\n",
    "    output_dir=os.path.join(CONFIG[\"models_dir\"], \"pt_to_ta\"),\n",
    "    direction=\"pt_to_ta\"\n",
    ")\n",
    "\n",
    "train_result_pt_ta = trainer_pt_ta.train()\n",
    "\n",
    "print(\"\\n=== Treinamento PT ‚Üí TA Conclu√≠do ===\")\n",
    "print(f\"√âpocas: {train_result_pt_ta.metrics.get('epoch', 'N/A')}\")\n",
    "print(f\"Loss final: {train_result_pt_ta.metrics.get('train_loss', 'N/A'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78fa2a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar modelo PT -> TA\n",
    "model_pt_ta.save_pretrained(os.path.join(CONFIG[\"models_dir\"], \"pt_to_ta_final\"))\n",
    "tokenizer.save_pretrained(os.path.join(CONFIG[\"models_dir\"], \"pt_to_ta_final\"))\n",
    "print(f\"Modelo PT ‚Üí TA salvo em {CONFIG['models_dir']}/pt_to_ta_final/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe78c44",
   "metadata": {},
   "source": [
    "### 8.2 Fine-Tuning: Tupi Antigo ‚Üí Portugu√™s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8fa293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liberar mem√≥ria do modelo anterior\n",
    "del model_pt_ta, trainer_pt_ta\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "# Tokenizar datasets para TA -> PT\n",
    "print(\"Tokenizando datasets para TA ‚Üí PT...\")\n",
    "tokenized_train_ta_pt = dataset_dict[\"train\"].map(preprocess_ta_to_pt, batched=True)\n",
    "tokenized_val_ta_pt = dataset_dict[\"validation\"].map(preprocess_ta_to_pt, batched=True)\n",
    "\n",
    "print(f\"Treino: {len(tokenized_train_ta_pt)} exemplos\")\n",
    "print(f\"Valida√ß√£o: {len(tokenized_val_ta_pt)} exemplos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7557fbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelo base para TA -> PT\n",
    "print(\"Carregando modelo base para fine-tuning TA ‚Üí PT...\")\n",
    "model_ta_pt = MBartForConditionalGeneration.from_pretrained(\n",
    "    CONFIG[\"model_checkpoint\"],\n",
    "    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    ")\n",
    "\n",
    "# Aplicar LoRA\n",
    "model_ta_pt = get_peft_model(model_ta_pt, lora_config)\n",
    "model_ta_pt.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treinar modelo TA -> PT\n",
    "print(\"Iniciando treinamento TA ‚Üí PT...\")\n",
    "trainer_ta_pt = create_trainer(\n",
    "    model=model_ta_pt,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=tokenized_train_ta_pt,\n",
    "    val_dataset=tokenized_val_ta_pt,\n",
    "    output_dir=os.path.join(CONFIG[\"models_dir\"], \"ta_to_pt\"),\n",
    "    direction=\"ta_to_pt\"\n",
    ")\n",
    "\n",
    "train_result_ta_pt = trainer_ta_pt.train()\n",
    "\n",
    "print(\"\\n=== Treinamento TA ‚Üí PT Conclu√≠do ===\")\n",
    "print(f\"√âpocas: {train_result_ta_pt.metrics.get('epoch', 'N/A')}\")\n",
    "print(f\"Loss final: {train_result_ta_pt.metrics.get('train_loss', 'N/A'):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a735249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar modelo TA -> PT\n",
    "model_ta_pt.save_pretrained(os.path.join(CONFIG[\"models_dir\"], \"ta_to_pt_final\"))\n",
    "tokenizer.save_pretrained(os.path.join(CONFIG[\"models_dir\"], \"ta_to_pt_final\"))\n",
    "print(f\"Modelo TA ‚Üí PT salvo em {CONFIG['models_dir']}/ta_to_pt_final/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7ef53e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Avalia√ß√£o dos Modelos Fine-Tuned\n",
    "\n",
    "Agora avaliamos os modelos treinados no conjunto de teste, que nunca foi usado durante o treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b45418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar modelos fine-tuned para avalia√ß√£o\n",
    "from peft import PeftModel\n",
    "\n",
    "def load_finetuned_model(model_path):\n",
    "    \"\"\"Carrega um modelo fine-tuned com LoRA.\"\"\"\n",
    "    base_model = MBartForConditionalGeneration.from_pretrained(\n",
    "        CONFIG[\"model_checkpoint\"],\n",
    "        torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(base_model, model_path)\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Carregar modelos\n",
    "print(\"Carregando modelos fine-tuned...\")\n",
    "model_pt_ta_ft = load_finetuned_model(os.path.join(CONFIG[\"models_dir\"], \"pt_to_ta_final\"))\n",
    "print(\"  ‚úì Modelo PT ‚Üí TA carregado\")\n",
    "\n",
    "model_ta_pt_ft = load_finetuned_model(os.path.join(CONFIG[\"models_dir\"], \"ta_to_pt_final\"))\n",
    "print(\"  ‚úì Modelo TA ‚Üí PT carregado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ca6018",
   "metadata": {},
   "source": [
    "### 9.1 Avalia√ß√£o PT ‚Üí TA (Fine-Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca39e3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar PT -> TA (fine-tuned)\n",
    "print(\"Traduzindo PT ‚Üí TA (fine-tuned)...\")\n",
    "translations_pt_ta_ft = translate_batch(\n",
    "    model_pt_ta_ft,\n",
    "    test_portuguese,\n",
    "    source_lang=LANG_CODE,\n",
    "    target_lang=LANG_CODE\n",
    ")\n",
    "\n",
    "metrics_pt_ta_ft = compute_all_metrics(translations_pt_ta_ft, test_tupi_ref)\n",
    "\n",
    "print(\"\\n=== M√©tricas Fine-Tuned PT ‚Üí TA ===\")\n",
    "print(f\"  BLEU:  {metrics_pt_ta_ft['bleu']:.2f}\")\n",
    "print(f\"  chrF1: {metrics_pt_ta_ft['chrf1']:.2f}\")\n",
    "print(f\"  chrF3: {metrics_pt_ta_ft['chrf3']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb750a",
   "metadata": {},
   "source": [
    "### 9.2 Avalia√ß√£o TA ‚Üí PT (Fine-Tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2b7bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar TA -> PT (fine-tuned)\n",
    "print(\"Traduzindo TA ‚Üí PT (fine-tuned)...\")\n",
    "translations_ta_pt_ft = translate_batch(\n",
    "    model_ta_pt_ft,\n",
    "    test_tupi,\n",
    "    source_lang=LANG_CODE,\n",
    "    target_lang=LANG_CODE\n",
    ")\n",
    "\n",
    "metrics_ta_pt_ft = compute_all_metrics(translations_ta_pt_ft, test_portuguese_ref)\n",
    "\n",
    "print(\"\\n=== M√©tricas Fine-Tuned TA ‚Üí PT ===\")\n",
    "print(f\"  BLEU:  {metrics_ta_pt_ft['bleu']:.2f}\")\n",
    "print(f\"  chrF1: {metrics_ta_pt_ft['chrf1']:.2f}\")\n",
    "print(f\"  chrF3: {metrics_ta_pt_ft['chrf3']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac903b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Salvar resultados few-shot\n",
    "results_few_shot = {\n",
    "    \"pt_to_ta\": {\n",
    "        \"bleu\": metrics_pt_ta_ft[\"bleu\"],\n",
    "        \"chrf1\": metrics_pt_ta_ft[\"chrf1\"],\n",
    "        \"chrf3\": metrics_pt_ta_ft[\"chrf3\"],\n",
    "        \"bleu_details\": metrics_pt_ta_ft[\"bleu_details\"]\n",
    "    },\n",
    "    \"ta_to_pt\": {\n",
    "        \"bleu\": metrics_ta_pt_ft[\"bleu\"],\n",
    "        \"chrf1\": metrics_ta_pt_ft[\"chrf1\"],\n",
    "        \"chrf3\": metrics_ta_pt_ft[\"chrf3\"],\n",
    "        \"bleu_details\": metrics_ta_pt_ft[\"bleu_details\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Salvar em arquivo JSON\n",
    "with open(os.path.join(CONFIG[\"results_dir\"], \"results_few_shot.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results_few_shot, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"Resultados few-shot salvos em results/results_few_shot.json\")\n",
    "\n",
    "# Salvar tradu√ß√µes\n",
    "os.makedirs(os.path.join(CONFIG[\"results_dir\"], \"outputs_few_shot\"), exist_ok=True)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"source\": test_portuguese,\n",
    "    \"reference\": test_tupi_ref,\n",
    "    \"translation\": translations_pt_ta_ft\n",
    "}).to_csv(os.path.join(CONFIG[\"results_dir\"], \"outputs_few_shot\", \"pt_to_ta.csv\"), index=False)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"source\": test_tupi,\n",
    "    \"reference\": test_portuguese_ref,\n",
    "    \"translation\": translations_ta_pt_ft\n",
    "}).to_csv(os.path.join(CONFIG[\"results_dir\"], \"outputs_few_shot\", \"ta_to_pt.csv\"), index=False)\n",
    "\n",
    "print(\"Tradu√ß√µes salvas em results/outputs_few_shot/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aec88ee",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 10. Compara√ß√£o: Zero-Shot vs Fine-Tuned\n",
    "\n",
    "### Matriz Comparativa de M√©tricas\n",
    "\n",
    "Comparamos os resultados obtidos nos dois regimes (zero-shot e few-shot) para ambas as dire√ß√µes de tradu√ß√£o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc786c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar matriz comparativa\n",
    "comparison_data = {\n",
    "    \"Dire√ß√£o\": [\"PT ‚Üí TA\", \"PT ‚Üí TA\", \"TA ‚Üí PT\", \"TA ‚Üí PT\"],\n",
    "    \"Modo\": [\"Zero-Shot\", \"Fine-Tuned\", \"Zero-Shot\", \"Fine-Tuned\"],\n",
    "    \"BLEU\": [\n",
    "        metrics_pt_ta_zero[\"bleu\"],\n",
    "        metrics_pt_ta_ft[\"bleu\"],\n",
    "        metrics_ta_pt_zero[\"bleu\"],\n",
    "        metrics_ta_pt_ft[\"bleu\"]\n",
    "    ],\n",
    "    \"chrF1\": [\n",
    "        metrics_pt_ta_zero[\"chrf1\"],\n",
    "        metrics_pt_ta_ft[\"chrf1\"],\n",
    "        metrics_ta_pt_zero[\"chrf1\"],\n",
    "        metrics_ta_pt_ft[\"chrf1\"]\n",
    "    ],\n",
    "    \"chrF3\": [\n",
    "        metrics_pt_ta_zero[\"chrf3\"],\n",
    "        metrics_pt_ta_ft[\"chrf3\"],\n",
    "        metrics_ta_pt_zero[\"chrf3\"],\n",
    "        metrics_ta_pt_ft[\"chrf3\"]\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "print(\"=== Matriz Comparativa de M√©tricas ===\\n\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Calcular melhorias\n",
    "print(\"\\n\\n=== Melhoria com Fine-Tuning ===\")\n",
    "print(f\"\\nPT ‚Üí TA:\")\n",
    "print(f\"  BLEU:  {metrics_pt_ta_ft['bleu'] - metrics_pt_ta_zero['bleu']:+.2f} pontos\")\n",
    "print(f\"  chrF1: {metrics_pt_ta_ft['chrf1'] - metrics_pt_ta_zero['chrf1']:+.2f} pontos\")\n",
    "print(f\"  chrF3: {metrics_pt_ta_ft['chrf3'] - metrics_pt_ta_zero['chrf3']:+.2f} pontos\")\n",
    "\n",
    "print(f\"\\nTA ‚Üí PT:\")\n",
    "print(f\"  BLEU:  {metrics_ta_pt_ft['bleu'] - metrics_ta_pt_zero['bleu']:+.2f} pontos\")\n",
    "print(f\"  chrF1: {metrics_ta_pt_ft['chrf1'] - metrics_ta_pt_zero['chrf1']:+.2f} pontos\")\n",
    "print(f\"  chrF3: {metrics_ta_pt_ft['chrf3'] - metrics_ta_pt_zero['chrf3']:+.2f} pontos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d535f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza√ß√£o gr√°fica\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    metrics_names = [\"BLEU\", \"chrF1\", \"chrF3\"]\n",
    "    x = np.arange(2)\n",
    "    width = 0.35\n",
    "    \n",
    "    for idx, metric in enumerate(metrics_names):\n",
    "        ax = axes[idx]\n",
    "        zero_shot = [metrics_pt_ta_zero[metric.lower()], metrics_ta_pt_zero[metric.lower()]]\n",
    "        fine_tuned = [metrics_pt_ta_ft[metric.lower()], metrics_ta_pt_ft[metric.lower()]]\n",
    "        \n",
    "        bars1 = ax.bar(x - width/2, zero_shot, width, label='Zero-Shot', color='#ff7f0e')\n",
    "        bars2 = ax.bar(x + width/2, fine_tuned, width, label='Fine-Tuned', color='#1f77b4')\n",
    "        \n",
    "        ax.set_xlabel('Dire√ß√£o')\n",
    "        ax.set_ylabel('Score')\n",
    "        ax.set_title(f'{metric}')\n",
    "        ax.set_xticks(x)\n",
    "        ax.set_xticklabels(['PT ‚Üí TA', 'TA ‚Üí PT'])\n",
    "        ax.legend()\n",
    "        ax.set_ylim(0, 100)\n",
    "        \n",
    "        # Adicionar valores nas barras\n",
    "        for bar in bars1 + bars2:\n",
    "            height = bar.get_height()\n",
    "            ax.annotate(f'{height:.1f}',\n",
    "                       xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                       xytext=(0, 3),\n",
    "                       textcoords=\"offset points\",\n",
    "                       ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.suptitle('Compara√ß√£o: Zero-Shot vs Fine-Tuned', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(CONFIG[\"results_dir\"], \"comparison_chart.png\"), dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"\\nGr√°fico salvo em {CONFIG['results_dir']}/comparison_chart.png\")\n",
    "except ImportError:\n",
    "    print(\"matplotlib n√£o dispon√≠vel para visualiza√ß√£o gr√°fica\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bc6ac3",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 11. Exemplos Qualitativos\n",
    "\n",
    "Analisamos algumas tradu√ß√µes para entender qualitativamente o desempenho dos modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos qualitativos PT -> TA\n",
    "print(\"=\" * 80)\n",
    "print(\"EXEMPLOS QUALITATIVOS: Portugu√™s ‚Üí Tupi Antigo\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "n_examples = min(10, len(test_portuguese))\n",
    "for i in range(n_examples):\n",
    "    print(f\"\\n--- Exemplo {i+1} ---\")\n",
    "    print(f\"üìù Fonte (PT):      {test_portuguese[i]}\")\n",
    "    print(f\"‚úÖ Refer√™ncia (TA): {test_tupi_ref[i]}\")\n",
    "    print(f\"üî¥ Zero-Shot:       {translations_pt_ta_zero[i]}\")\n",
    "    print(f\"üü¢ Fine-Tuned:      {translations_pt_ta_ft[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff541535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplos qualitativos TA -> PT\n",
    "print(\"=\" * 80)\n",
    "print(\"EXEMPLOS QUALITATIVOS: Tupi Antigo ‚Üí Portugu√™s\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i in range(n_examples):\n",
    "    print(f\"\\n--- Exemplo {i+1} ---\")\n",
    "    print(f\"üìù Fonte (TA):      {test_tupi[i]}\")\n",
    "    print(f\"‚úÖ Refer√™ncia (PT): {test_portuguese_ref[i]}\")\n",
    "    print(f\"üî¥ Zero-Shot:       {translations_ta_pt_zero[i]}\")\n",
    "    print(f\"üü¢ Fine-Tuned:      {translations_ta_pt_ft[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27dc9314",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 12. Discuss√£o e Limita√ß√µes\n",
    "\n",
    "### 12.1 An√°lise dos Resultados\n",
    "\n",
    "#### Zero-Shot (NLLB + Guarani)\n",
    "- Utilizamos o modelo NLLB-200 com Guarani como l√≠ngua proxy para Tupi Antigo\n",
    "- O Guarani pertence √† mesma fam√≠lia lingu√≠stica (Tupi-Guarani), o que permite alguma transfer√™ncia\n",
    "- A transforma√ß√£o `√± ‚Üí nh` aproxima a ortografia do Guarani moderno ao Tupi Antigo hist√≥rico\n",
    "- Mesmo assim, os resultados s√£o limitados devido √†s diferen√ßas significativas entre as l√≠nguas\n",
    "\n",
    "#### Fine-Tuned (mBART + LoRA)\n",
    "- O fine-tuning com LoRA permite adaptar o modelo mBART ao par Portugu√™s-Tupi Antigo\n",
    "- Mesmo com um corpus pequeno, observamos melhoria significativa nas m√©tricas\n",
    "- O modelo aprende padr√µes espec√≠ficos da l√≠ngua Tupi, incluindo sua morfologia\n",
    "\n",
    "### 12.2 Limita√ß√µes\n",
    "\n",
    "1. **Tamanho do Corpus**: Corpora de baixo recurso limitam o aprendizado do modelo\n",
    "\n",
    "2. **Diferen√ßa Guarani/Tupi**: Apesar de relacionadas, s√£o l√≠nguas distintas com diferen√ßas significativas\n",
    "\n",
    "3. **Tokeniza√ß√£o**: Os tokenizadores n√£o foram otimizados para Tupi Antigo\n",
    "\n",
    "4. **Varia√ß√£o Ortogr√°fica**: O Tupi Antigo possui varia√ß√µes hist√≥ricas que podem confundir o modelo\n",
    "\n",
    "5. **Avalia√ß√£o Autom√°tica**: M√©tricas como BLEU podem n√£o capturar adequadamente a qualidade sem√¢ntica\n",
    "\n",
    "### 12.3 Trabalhos Futuros\n",
    "\n",
    "1. Expandir o corpus paralelo\n",
    "2. Desenvolver um tokenizador espec√≠fico para Tupi Antigo\n",
    "3. Explorar outras l√≠nguas da fam√≠lia Tupi-Guarani dispon√≠veis no NLLB\n",
    "4. Realizar avalia√ß√£o humana das tradu√ß√µes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7d6672",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Conclus√£o\n",
    "\n",
    "Neste EP, implementamos e avaliamos tradutores autom√°ticos para o par lingu√≠stico **Portugu√™s ‚Üî Tupi Antigo** em dois regimes:\n",
    "\n",
    "### Principais Resultados\n",
    "\n",
    "1. **Zero-Shot**: O modelo mBART pr√©-treinado n√£o consegue traduzir adequadamente para/de Tupi Antigo sem fine-tuning, confirmando a necessidade de adapta√ß√£o para l√≠nguas de baixo recurso.\n",
    "\n",
    "2. **Fine-Tuned**: Com fine-tuning usando LoRA, observamos melhorias significativas em todas as m√©tricas, demonstrando que mesmo corpora pequenos podem ser √∫teis para adaptar modelos multil√≠ngues.\n",
    "\n",
    "3. **Dire√ß√£o da Tradu√ß√£o**: A tradu√ß√£o TA ‚Üí PT tende a ter melhores resultados, possivelmente porque o portugu√™s √© uma l√≠ngua bem representada no modelo base.\n",
    "\n",
    "### Arquivos Gerados\n",
    "\n",
    "- `results/results_zero_shot.json`: M√©tricas do regime zero-shot\n",
    "- `results/results_few_shot.json`: M√©tricas do regime few-shot\n",
    "- `results/outputs_zero_shot/`: Tradu√ß√µes geradas (zero-shot)\n",
    "- `results/outputs_few_shot/`: Tradu√ß√µes geradas (fine-tuned)\n",
    "- `models/pt_to_ta_final/`: Modelo fine-tuned PT ‚Üí TA\n",
    "- `models/ta_to_pt_final/`: Modelo fine-tuned TA ‚Üí PT\n",
    "- `data/train.csv`, `data/val.csv`, `data/test.csv`: Divis√µes do corpus\n",
    "\n",
    "---\n",
    "\n",
    "**MAC0508 ‚Äî Introdu√ß√£o ao Processamento de L√≠ngua Natural**  \n",
    "**EP2 ‚Äî Tradu√ß√£o Autom√°tica de Baixo Recurso**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8319351c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resumo final dos resultados\n",
    "print(\"=\" * 60)\n",
    "print(\"RESUMO FINAL DOS RESULTADOS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìä M√âTRICAS FINAIS\\n\")\n",
    "print(f\"{'Cen√°rio':<25} {'BLEU':>10} {'chrF1':>10} {'chrF3':>10}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'PT‚ÜíTA Zero-Shot':<25} {metrics_pt_ta_zero['bleu']:>10.2f} {metrics_pt_ta_zero['chrf1']:>10.2f} {metrics_pt_ta_zero['chrf3']:>10.2f}\")\n",
    "print(f\"{'PT‚ÜíTA Fine-Tuned':<25} {metrics_pt_ta_ft['bleu']:>10.2f} {metrics_pt_ta_ft['chrf1']:>10.2f} {metrics_pt_ta_ft['chrf3']:>10.2f}\")\n",
    "print(f\"{'TA‚ÜíPT Zero-Shot':<25} {metrics_ta_pt_zero['bleu']:>10.2f} {metrics_ta_pt_zero['chrf1']:>10.2f} {metrics_ta_pt_zero['chrf3']:>10.2f}\")\n",
    "print(f\"{'TA‚ÜíPT Fine-Tuned':<25} {metrics_ta_pt_ft['bleu']:>10.2f} {metrics_ta_pt_ft['chrf1']:>10.2f} {metrics_ta_pt_ft['chrf3']:>10.2f}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "print(\"\\n‚úÖ Notebook executado com sucesso!\")\n",
    "print(f\"üìÅ Resultados salvos em: {CONFIG['results_dir']}/\")\n",
    "print(f\"ü§ñ Modelos salvos em: {CONFIG['models_dir']}/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
